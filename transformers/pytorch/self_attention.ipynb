{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Transformers\n",
    "\n",
    "Self-attention focuses only on the input and captures only dependencies between the input\n",
    "elements.\n",
    "\n",
    "#### Basic self-attention\n",
    "\n",
    "Let’s assume we have an input sequence of length T, x(1) , ... , x(T) , as well\n",
    "as an output sequence, z(1) , z(2) , ... , z(T) . We will use **o** as whole transformer output and **z** as the output of the self-attention layer (it's an intermediate step in the model).\n",
    "Each *i*th element in these sequences are vectors of size *d* representing the feature information for the input at position *i*.\n",
    "\n",
    "For seq2seq task, goal of self-attention is to model the dependencies of the current input element to all other input elements. To achieve this, self-attention mechanisms are composed of three stages. First, we derive importance weights based on the similarity between the current element and all other elements in the sequence. Second, we normalize the weights, which usually involves the use of the already familiar softmax function. Third, we use these weights in combination with the corresponding sequence elements to compute the attention value.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Calculating similarity values ω<sub>ij<sub>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8, 16])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence mapped to an integer representation via a dictionary\n",
    "sentence = torch.tensor(\n",
    "    [0, # can\n",
    "     7, # you\n",
    "     1, # help\n",
    "     2, # me\n",
    "     5, # to\n",
    "     6, # translate\n",
    "     4, # this\n",
    "     3] # sentence\n",
    ")\n",
    "\n",
    "# produce embeddings\n",
    "torch.manual_seed(123)\n",
    "embed = torch.nn.Embedding(10, 16)  # dict size, emb dim\n",
    "embed_sentence = embed(sentence).detach()\n",
    "embed_sentence.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([8, 8])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute ω\n",
    "omega = torch.empty(8, 8)\n",
    "for i, x_i in enumerate(embed_sentence):\n",
    " for j, x_j in enumerate(embed_sentence):\n",
    "  omega[i, j] = torch.dot(x_i, x_j)\n",
    "\n",
    "# equivalent to matrix multiplication of input sequence:\n",
    "omega_mat = embed_sentence.matmul(embed_sentence.T)\n",
    "\n",
    "# check if the same\n",
    "print(torch.allclose(omega_mat, omega))\n",
    "omega.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Calculating attention weights α<sub>ij<sub>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "attention_weights = F.softmax(omega, dim=1)\n",
    "# check if sum in rows is 1\n",
    "#attention_weights.sum(dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Calculating context vectors z<sup>(i)<sup>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = embed_sentence[1,:]\n",
    "context_vec_2 = torch.zeros(x_2.shape)\n",
    "for j in range(8):\n",
    " x_j = embed_sentence[j, :]\n",
    " context_vec_2 += attention_weights[1, j] * x_j\n",
    "x_2.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8]) torch.Size([8, 16])\n"
     ]
    }
   ],
   "source": [
    "# matrix mul\n",
    "print(attention_weights.shape, embed_sentence.shape)\n",
    "\n",
    "context_vec = torch.matmul(attention_weights, embed_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Parameterizing the self-attention mechanism: scaled dot-product attention"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "d = embed_sentence.shape[1]\n",
    "U_q = torch.rand(d, d)\n",
    "U_k = torch.rand(d, d)\n",
    "U_v = torch.rand(d, d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# Example for x^(2)\n",
    "x_2 = embed_sentence[1]\n",
    "\n",
    "# query sentence\n",
    "query_2 = U_q.matmul(x_2)\n",
    "# key sentence\n",
    "key_2 = U_q.matmul(x_2)\n",
    "# value sentence\n",
    "value_2 = U_q.matmul(x_2)\n",
    "\n",
    "# for all input elements\n",
    "keys = U_k.matmul(embed_sentence.T).T\n",
    "values = U_v.matmul(embed_sentence.T).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(14.3667)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here omega is calculated as dot product of query and key\n",
    "omega_23 = query_2.dot(keys[2])\n",
    "omega_23"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x16 and 8x16)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-47-866c8ccf32d4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0momega_2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mquery_2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0momega_2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (1x16 and 8x16)"
     ]
    }
   ],
   "source": [
    "omega_2 = query_2.matmul(keys.T)\n",
    "omega_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "attention_weights_2 = F.softmax(omega_2 / d**0.5, dim=0)\n",
    "# output\n",
    "context_vector_2 = attention_weights_2.matmul(values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}