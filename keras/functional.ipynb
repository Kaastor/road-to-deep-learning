{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functional API\n",
    "\n",
    "Makes you use layers as functions (take tensors and return tensors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "input_tensor = layers.Input(shape=(32,))  # tensor\n",
    "dense = layers.Dense(32, activation='relu')  # layer as function\n",
    "output_tensor = dense(input_tensor)  # layer called on a tensor, returns tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-input models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "text -> embedd -> LSTM ------\\\\\n",
    "question -> embedd -> LSTM  --> concatenate -> dense -> answer\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 10000)  640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 10000)  320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 32)           1284224     embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 16)           641088      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 48)           0           lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 500)          24500       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,909,812\n",
      "Trainable params: 2,909,812\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# first input to the model\n",
    "text_input = layers.Input(shape=(None,), dtype='int32', name='text')\n",
    "embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "# second input to the model\n",
    "question_input = layers.Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_quest = layers.Embedding(32, question_vocabulary_size)(question_input)\n",
    "encoded_quest = layers.LSTM(16)(embedded_quest)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_quest], axis=-1)\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_len = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_len))\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_len))\n",
    "answers = np.random.randint(0, 1, size=(num_samples, max_len))\n",
    "\n",
    "model.fit([text, question], answers,\n",
    "          epochs=10,\n",
    "          batch_size=128)\n",
    "# or if inputs are named:\n",
    "model.fit({'text': text, 'question': question}, answers,\n",
    "          epochs=10,\n",
    "          batch_size=128)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-output (head) models\n",
    "\n",
    "A simple example is a network that attempts to simultaneously\n",
    "predict different properties of the data, such as a network that takes as input a series\n",
    "of social media posts from a single anonymous person and tries to predict attributes of\n",
    "that person, such as age, gender, and income level.\n",
    "\n",
    "Social media post -> 1D ConvNet\n",
    "\n",
    "-> Dense -> Age\n",
    "-> Dense -> Income\n",
    "-> Dense -> Gender"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "# 1D ConvNet\n",
    "posts_input = layers.Input(shape=(None, ), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# heads\n",
    "age_prediction = layers.Dense(1, activation='sigmoid', name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importantly, training such a model requires the ability to specify different loss func-\n",
    "tions for different heads of the network: for instance, age prediction is a scalar regres-\n",
    "sion task, but gender prediction is a binary classification task, requiring a different\n",
    "training procedure. But because gradient descent requires you to minimize a scalar,\n",
    "you must combine these losses into a single value in order to train the model. The\n",
    "simplest way to combine different losses is to sum them all."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "# or if inputs are named:\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that very imbalanced loss contributions will cause the model representations to\n",
    "be optimized preferentially for the task with the largest individual loss, at the expense\n",
    "of the other tasks. To remedy this, you can assign different levels of importance to the\n",
    "loss values in their contribution to the final loss. This is useful in particular if the\n",
    "losses’ values use different scales. For instance, the mean squared error ( MSE ) loss\n",
    "used for the age-regression task typically takes a value around 3–5, whereas the cross-\n",
    "entropy loss used for the gender-classification task can be as low as 0.1. In such a situa-\n",
    "tion, to balance the contribution of the different losses, you can assign a weight of 10\n",
    "to the crossentropy loss and a weight of 0.25 to the MSE loss."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[0.25, 1., 10.])\n",
    "# or if inputs are named:\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'},\n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.,\n",
    "                            'gender': 10.})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/training.py:787 train_step\n        y_pred = self(x, training=True)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/functional.py:415 call\n        inputs, training=training, mask=mask)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/layers/convolutional.py:249 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py:1138 convolution_v2\n        name=name)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py:1268 convolution_internal\n        name=name)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:617 new_func\n        return func(*args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:617 new_func\n        return func(*args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py:2011 conv1d\n        name=name)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py:973 conv2d\n        data_format=data_format, dilations=dilations, name=name)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py:601 _create_op_internal\n        compute_device)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:3569 _create_op_internal\n        op_def=op_def)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:2042 __init__\n        control_input_ops, op_def)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 5 from 1 for '{{node model_2/conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](model_2/conv1d/conv1d/ExpandDims, model_2/conv1d/conv1d/ExpandDims_1)' with input shapes: [?,1,1,50000], [1,5,50000,128].\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-bf8e0f3b693f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mposts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mempty\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m;\u001B[0m \u001B[0mage_targets\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mempty\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m;\u001B[0m \u001B[0mincome_targets\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mempty\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m;\u001B[0m \u001B[0mgender_targets\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mempty\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m model.fit(posts, [age_targets, income_targets, gender_targets],\n\u001B[0;32m----> 5\u001B[0;31m           epochs=10, batch_size=64)\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m model.fit(posts, {'age': age_targets,\n",
      "\u001B[0;32m~/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1182\u001B[0m                 _r=1):\n\u001B[1;32m   1183\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1184\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1185\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1186\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    883\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    884\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 885\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    886\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    887\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    931\u001B[0m       \u001B[0;31m# This is the first call of __call__, so we have to initialize.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    932\u001B[0m       \u001B[0minitializers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 933\u001B[0;31m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_initialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madd_initializers_to\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitializers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    934\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    935\u001B[0m       \u001B[0;31m# At this point we know that the initialization is complete (or less\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_initialize\u001B[0;34m(self, args, kwds, add_initializers_to)\u001B[0m\n\u001B[1;32m    758\u001B[0m     self._concrete_stateful_fn = (\n\u001B[1;32m    759\u001B[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001B[0;32m--> 760\u001B[0;31m             *args, **kwds))\n\u001B[0m\u001B[1;32m    761\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    762\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minvalid_creator_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0munused_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0munused_kwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_get_concrete_function_internal_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3064\u001B[0m       \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3065\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3066\u001B[0;31m       \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3067\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3068\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3461\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3462\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3463\u001B[0;31m           \u001B[0mgraph_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3464\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3465\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3306\u001B[0m             \u001B[0marg_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0marg_names\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3307\u001B[0m             \u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3308\u001B[0;31m             capture_by_value=self._capture_by_value),\n\u001B[0m\u001B[1;32m   3309\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_attributes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3310\u001B[0m         \u001B[0mfunction_spec\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_spec\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001B[0m\n\u001B[1;32m   1005\u001B[0m         \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1006\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1007\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1008\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1009\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    666\u001B[0m         \u001B[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    667\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcompile_with_xla\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 668\u001B[0;31m           \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    669\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    670\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    992\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    993\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 994\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    995\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    996\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/training.py:787 train_step\n        y_pred = self(x, training=True)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/functional.py:415 call\n        inputs, training=training, mask=mask)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/keras/layers/convolutional.py:249 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py:1138 convolution_v2\n        name=name)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py:1268 convolution_internal\n        name=name)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:617 new_func\n        return func(*args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:617 new_func\n        return func(*args, **kwargs)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py:2011 conv1d\n        name=name)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py:973 conv2d\n        data_format=data_format, dilations=dilations, name=name)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py:601 _create_op_internal\n        compute_device)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:3569 _create_op_internal\n        op_def=op_def)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:2042 __init__\n        control_input_ops, op_def)\n    /home/przemek/Deep Learning/road-to-deep-learning/road-to-deep-learning/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 5 from 1 for '{{node model_2/conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](model_2/conv1d/conv1d/ExpandDims, model_2/conv1d/conv1d/ExpandDims_1)' with input shapes: [?,1,1,50000], [1,5,50000,128].\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(posts, [age_targets, income_targets, gender_targets],\n",
    "          epochs=10, batch_size=64)\n",
    "\n",
    "model.fit(posts, {'age': age_targets,\n",
    "                  'income': income_targets,\n",
    "                  'gender': gender_targets},\n",
    "          epochs=10, batch_size=64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}